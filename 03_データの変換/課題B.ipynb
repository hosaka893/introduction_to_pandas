{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 0. 事前準備\n",
    "\n",
    "特にありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import branca.colormap as cm\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "import folium\n",
    "from geopy.distance import geodesic\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. データ型の変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikipediaの「List of people who died climbing Mount Everest」からエベレスト登山死者データを取得します。\n",
    "\n",
    "URL:  \n",
    "https://en.wikipedia.org/wiki/List_of_people_who_died_climbing_Mount_Everest\n",
    "\n",
    "データの取得方法:  \n",
    "`pd.read_html()`に上記URLを指定するとページ上にあるすべての`table`タグのデータがデータフレームの配列として取得できますので、そこから必要なデータフレームを選択します。\n",
    "\n",
    "ただし、Pythonのバージョンによってはエラーとなってデータが取得できない場合があります。\n",
    "その場合は以下のGitHubのスレッドにあるように、`requests.get()`でHTMLを取得してから`pd.read_html()`を試してください。  \n",
    "https://github.com/pandas-dev/pandas/issues/21499\n",
    "\n",
    "データの保存:  \n",
    "取得後はセルを実行のたびに何度も取得しないよう、該当データフレームを`to_csv()`でCSVファイルにして、`data/list_of_people_who_died_climbing_mount_everest.csv`に保存します。\n",
    "\n",
    "次回以降のセル実行ではファイルが存在する場合、ファイルからデータを読み込むようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everest_death_wikipedia_url = 'https://en.wikipedia.org/wiki/List_of_people_who_died_climbing_Mount_Everest'\n",
    "everest_death_csv_path = 'data/list_of_people_who_died_climbing_mount_everest.csv'\n",
    "\n",
    "try:\n",
    "    everest_death_df = pd.read_csv(everest_death_csv_path)\n",
    "    print(f\"ファイル'{everest_death_csv_path}'からデータを取得しました。\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ファイル'{everest_death_csv_path}'が存在しないためウィキペディアからデータを取得します。\")\n",
    "    everest_death_html = requests.get(everest_death_wikipedia_url)\n",
    "    everest_death_df = pd.read_html(everest_death_html.text)[1]\n",
    "    everest_death_df.to_csv(everest_death_csv_path, index=False)\n",
    "    \n",
    "len(everest_death_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの中身を確認。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everest_death_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特に問題なくデータを取得できているようですが、`Refs`列は必要ないので削除します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everest_death_df.drop(columns=['Refs'], inplace=True)\n",
    "\n",
    "everest_death_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの型と欠損を確認。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everest_death_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1. 日時型への変換\n",
    "\n",
    "まずは日付の変換をします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Date`は日時型ではないようですので日付のフォーマットを指定して日時型に変換し、新たな列の`death_date`に格納します。\n",
    "\n",
    "参考）  \n",
    "strftime() と strptime() の振る舞い  \n",
    "https://docs.python.org/ja/3/library/datetime.html#strftime-and-strptime-behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everest_death_df['death_date'] = pd.to_datetime(everest_death_df['Date'], format=\"%B %d, %Y\", errors='coerce')\n",
    "\n",
    "everest_death_df['death_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変換失敗がないか確認。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"「Date」のNA数:\", everest_death_df['Date'].isna().sum())\n",
    "print(\"「death_date」のNA数:\", everest_death_df['death_date'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "失敗が２件あるようなので、どんなデータで失敗しているかを確認。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everest_death_df[everest_death_df['death_date'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これはデータの問題なので、`death_date`を直接設定してしまいます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_index_list = everest_death_df[everest_death_df['death_date'].isna()].index\n",
    "\n",
    "everest_death_df.loc[na_index_list[0], 'death_date'] = pd.Timestamp(year=1934, month=5, day=31)\n",
    "\n",
    "everest_death_df.loc[na_index_list[1], 'death_date'] = \\\n",
    "    pd.Timestamp(year=1975, month=8, day=22) # 死亡日は22あたりにしておきます。\n",
    "\n",
    "everest_death_df.iloc[na_index_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "もう一度変換失敗がないか確認。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everest_death_df['Date'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "死亡年をX軸、死亡者数をY軸とした折れ線グラフを描いてみましょう。\n",
    "\n",
    "死亡年でグループ分けし、インデックスが`death_year`、列が`死亡者数`のデータフレームを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everest_death_groupby_death_year = everest_death_df.groupby(everest_death_df['death_date'].dt.year) \\\n",
    "                                    .agg(死亡者数=('No.', 'count'))\n",
    "\n",
    "# インデックス名を変更。\n",
    "everest_death_groupby_death_year.index.names = ['death_year']\n",
    "\n",
    "everest_death_groupby_death_year.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`death_year`の値が飛び飛びなので、欠けている年をすべて埋めることとします。\n",
    "\n",
    "まずはインデックスを日付型（各年の元旦）に変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everest_death_groupby_death_year.index = pd.to_datetime(everest_death_groupby_death_year.index, format=\"%Y\")\n",
    "\n",
    "everest_death_groupby_death_year.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "インデックスを日付型に変換したら、今度は`pd.asfreq()`を使って年の穴埋めを行います。\n",
    "\n",
    "`pd.asfreq()`の引数には以下を設定します。  \n",
    "・`freq`: 頻度を表すコード。ここでは毎年の開始日を表す`YS`を指定。  \n",
    "・`fill_value`: 値の穴埋め。死亡者無しなので0とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everest_death_groupby_death_year = everest_death_groupby_death_year.asfreq(freq='YS', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everest_death_groupby_death_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それではグラフを描画します。\n",
    "\n",
    "どんなことが読み取れますか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font=['MS Gothic', 'Hiragino Sans', 'TakaoPGothic']) # 日本語フォントは設定が必要\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 10))\n",
    "\n",
    "sns.lineplot(data=everest_death_groupby_death_year, x=\"death_year\", y=\"死亡者数\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2. 文字列型からカテゴリ型への変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今度は集計やグラフで使いやすいよう、`Nationality`をカテゴリ型に変換します。\n",
    "\n",
    "カテゴリ数が少ない場合、カテゴリ型に変換することでデータのサイズを小さくすることができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずはどんなデータが入っているか確認。\n",
    "\n",
    "何か読み取れることがありますか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everest_death_df['Nationality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カテゴリにするには少々数が多すぎるかもしれません。  \n",
    "一方で、`Nepal`、`India`の数が極端に多いことが分かります。\n",
    "\n",
    "そこで、今回は`Nepal`、`India`、`Others`の３つのカテゴリに分けることとします。\n",
    "\n",
    "まずはすべてのデータをカテゴリ型に変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everest_death_df['nationality_cat'] = everest_death_df['Nationality'].astype('category')\n",
    "\n",
    "everest_death_df['nationality_cat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新たに`Others`というカテゴリを追加します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everest_death_df['nationality_cat'] = everest_death_df['nationality_cat'].cat.add_categories('Others')\n",
    "\n",
    "everest_death_df['nationality_cat'].cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に`Nepal`, `India`以外のデータをすべて`Others`に置き換えてしまいます。\n",
    "\n",
    "その後、実際に変更されたことを`value_count()`で確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everest_death_df.loc[~everest_death_df['nationality_cat'].isin(['Nepal', 'India']), 'nationality_cat'] = 'Others'\n",
    "\n",
    "everest_death_df['nationality_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`value_counts()`で件数が0でも表示されるのは、カテゴリが存在するためです。\n",
    "\n",
    "未使用のカテゴリを`remove_unused_categories()`で削除し、もう一度`value_count()`を実行して削除されていることを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everest_death_df['nationality_cat'] = everest_death_df['nationality_cat'].cat.remove_unused_categories()\n",
    "\n",
    "everest_death_df['nationality_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先ほどと同じように、死亡年をX軸、死亡者数をY軸とした折れ線グラフを描いてみましょう。  \n",
    "ただし、今回は`nationality_cat`ごとに線を描画します。\n",
    "\n",
    "死亡年と`nationality_cat`でグループ化し、インデックスが`death_year`と`nationality_cat`、列が`死亡者数`のデータフレームを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_death_year_nationality = everest_death_df \\\n",
    "                                    .groupby([everest_death_df['death_date'].dt.year, 'nationality_cat']) \\\n",
    "                                    .agg(死亡者数=('No.', 'count'))\n",
    "\n",
    "# インデックス名を変更。\n",
    "groupby_death_year_nationality.index.names = ['death_year', 'nationality_cat']\n",
    "\n",
    "groupby_death_year_nationality.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先ほどと同じようにインデックスの死亡年の欠けている年をすべて埋め、死亡者数を0とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# death_yearの日付型への変換がしやすいよう、nationality_catをインデックスから外しておく。\n",
    "groupby_death_year_nationality = groupby_death_year_nationality.unstack(1)\n",
    "\n",
    "groupby_death_year_nationality.index = pd.to_datetime(groupby_death_year_nationality.index, format=\"%Y\")\n",
    "\n",
    "groupby_death_year_nationality = groupby_death_year_nationality.asfreq('YS', fill_value=0)\n",
    "\n",
    "groupby_death_year_nationality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に`death_year`、`nationality_cat`をインデックスから外し、`death_year`、`nationality_cat`、`死亡者数`の３つの列となるようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_death_year_nationality = groupby_death_year_nationality.stack().reset_index()\n",
    "\n",
    "groupby_death_year_nationality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは死亡年をX軸、死亡者数をY軸とした折れ線グラフを描画します。  \n",
    "凡例の順番を揃えるよう、`lineplot()`の引数に`hue_order=['Nepal', 'India', 'Others']`を渡します。\n",
    "\n",
    "どんなことが読み取れますか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### チャレンジしてみよう！！ ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 位置座標の変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここからはウィキペディアの「世界の山一覧 (高さ順)」にある山のデータを取得して、地図やグラフに表示してみましょう。\n",
    "\n",
    "URL:  \n",
    "[https://ja.wikipedia.org/wiki/世界の山一覧_(高さ順)](https://ja.wikipedia.org/wiki/世界の山一覧_(高さ順\\))  \n",
    "\n",
    "データの取得方法:  \n",
    "`pd.read_html()`に上記URLを指定するとページ上にあるすべての`table`タグのデータがデータフレームの配列として取得できますので、そこから必要なデータフレームを選択します。\n",
    "\n",
    "ただし、Pythonのバージョンによってはエラーとなってデータが取得できない場合があります。\n",
    "その場合は以下のGitHubのスレッドにあるように、`requests.get()`でHTMLを取得してから`pd.read_html()`を試してください。  \n",
    "https://github.com/pandas-dev/pandas/issues/21499\n",
    "\n",
    "\n",
    "データの保存:  \n",
    "取得後はセルを実行のたびに何度も取得しないよう、該当データフレームを`to_csv()`でCSVファイルにして、`data/highest_montains.csv`に保存します。  \n",
    "次回以降のセル実行ではファイルが存在する場合、ファイルからデータを読み込むようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_montains_wikipedia_url = 'https://ja.wikipedia.org/wiki/世界の山一覧_(高さ順)'\n",
    "highest_montains_csv_path = 'data/highest_montains.csv'\n",
    "\n",
    "try:\n",
    "    highest_montain_df = pd.read_csv(highest_montains_csv_path)\n",
    "    print(f\"ファイル'{highest_montains_csv_path}'からデータを取得しました。\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ファイル'{highest_montains_csv_path}'が存在しないためウィキペディアからデータを取得します。\")\n",
    "    highest_montains_html = requests.get(highest_montains_wikipedia_url)\n",
    "    highest_montain_df = pd.read_html(highest_montains_html.text)[1]\n",
    "    highest_montain_df.to_csv(highest_montains_csv_path, index=False)\n",
    "    \n",
    "len(highest_montain_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの中身を確認。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_montain_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さっと見て、明らかにおかしい以下の二点を修正します。\n",
    "\n",
    "1.エベレストの位置座標  \n",
    "　先頭に余計なコードが含まれてしまっているようなので除去します。\n",
    " \n",
    "2.存在しない列「Unnamed: 9」  \n",
    "　削除します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_montain_df.loc[0, '位置'] = re.sub(r'^.+?(?=北緯)', '', highest_montain_df.loc[0, '位置'])\n",
    "\n",
    "highest_montain_df.drop(columns=['Unnamed: 9'], inplace=True)\n",
    "\n",
    "highest_montain_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの型と欠損を確認します。\n",
    "\n",
    "順位に欠損が少々あります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "highest_montain_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "山を地図上で表示できるよう、位置座標の変換を行います。\n",
    "\n",
    "まずはデータを確認。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_montain_df['位置']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "フォーマットと「度・分・秒」と「度のみ」の両方の表記があることが分かりました。  \n",
    "（ブラウザでは「度・分・秒」表記しか見えないのでやや肩透かしでありますが、「度のみ」の数値を抽出します。）\n",
    "\n",
    "数値抽出のための正規表現を作り、列の中でマッチしないデータがないか確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r'.+\\\\ufeff / \\\\ufeff北緯(\\d+\\.\\d)度 東経(\\d+\\.\\d)度'\n",
    "\n",
    "regex = r'^.+北緯(\\d{2}\\.\\d{5})度 東経(\\d{2,3}\\.\\d{5})度$'\n",
    "(~highest_montain_df['位置'].str.match(regex)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "すべてにマッチするようであれば、`Series.str.extract()`で数値抽出をおこないます。\n",
    "\n",
    "抽出した数値はそれぞれ、新たな列`latitude`、`longitude`に格納します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_montain_df[['latitude', 'longitude']] = highest_montain_df['位置'].str.extract(regex).astype(np.float64)\n",
    "\n",
    "highest_montain_df[['位置', 'latitude', 'longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 地図上にデータを表示\n",
    "\n",
    "山を以下のルールに沿って地図上に表示してみます。\n",
    "- 山の位置に円を配置。\n",
    "- 円の色を高さに合わせて滑らかに色分けする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず滑らかな色分けのためのカラーマップを作成します。\n",
    "\n",
    "`cm.LinearColormap`クラスのコンストラクタに任意の色の配列、山の高さの最小値、最大値を渡してインスタンスを生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_elevation = highest_montain_df['高さ (メートル)'].min()\n",
    "max_elevation = highest_montain_df['高さ (メートル)'].max()\n",
    "\n",
    "linear = cm.LinearColormap(['yellow', 'orange', 'red'], vmin=min_elevation, vmax=max_elevation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは地図上に表示します。\n",
    "\n",
    "どんなことが読み取れますか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everest_coords = tuple(highest_montain_df.loc[0, ['latitude', 'longitude']].to_list())\n",
    "\n",
    "map = folium.Map(location=everest_coords, zoom_start=4, tiles=\"cartodbdark_matter\") # 地味な地図を選択。\n",
    "\n",
    "# 高い山が上に重なるようにソート。\n",
    "for i, row in highest_montain_df.sort_values('高さ (メートル)', ascending=True).iterrows():\n",
    "\n",
    "    popup_message_html = f\"\"\"\n",
    "    <p>山名: {row['山名']}</p>\n",
    "    <p>順位: {'' if math.isnan(row['順位']) else int(row['順位'])}</p>\n",
    "    <p>高さ: {row['高さ (メートル)']:,}m</p>\n",
    "    <p>位置: ({row['latitude']}, {row['longitude']})</p>\n",
    "    <p>初登頂年号: {row['初登頂年号']}</p>\n",
    "    \"\"\"\n",
    "    popup = folium.Popup(folium.IFrame(popup_message_html), min_width=400, max_width=400)\n",
    "\n",
    "    color = linear(row['高さ (メートル)'])\n",
    "    \n",
    "    folium.Circle(location=(row['latitude'], row['longitude']),\n",
    "                  radius=2000,\n",
    "                  color=color,\n",
    "                  fill_color=color,\n",
    "                  fill_opacity=1,\n",
    "                  weight=1.5,\n",
    "                  popup=popup\n",
    "                 ).add_to(map)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "地図では山の高さが認識しにくいので、棒グラフでも表示してみましょう。  \n",
    "地図と見比べやすいようにX軸を経度、Yを高さとします。\n",
    "\n",
    "8,000m峰はいくつありますか？  \n",
    "また、他にどんなことが読み取れますか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "\n",
    "sns.barplot(x='山名', y='高さ (メートル)', data=highest_montain_df.sort_values('longitude', ascending=True))\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d109c1022d0269bfeb1214b0bec2187ee8bc4e794779a7e71ed964fc39a480b6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
